---
title: "Alzheimer's Analysis"
author: "Sneha Jacob, Alina Bangash, Jeremy Udo, Sana Akhtar, Jake Schwartz"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage

## Introduction 
Our team decided to analyze the Alzheimer’s Disease dataset created by Rabei El Kharoua on Kaggle. We decided to proceed with this topic since Alzheimer’s is a very common illness without a cure that affects millions of people both directly and indirectly. This data set includes data from 2,149 patients and has 34 variables. 

\newpage


## Which factors are strongly associated with a diagnosis of Alzheimer’s Disease? 


# E.g. "1. Neural Networks (Jake Schwartz, Alina Akhtar)"

```{r}
alzheimers_data = alzheimers_data <- read.csv("alzheimers_disease_data.csv")
colnames(alzheimers_data)
table(alzheimers_data$Diagnosis)
```
# Initialize Model, 2 hidden layers, uses ReLU activation, and binary cross entropy with logits loss because it says in torch modules it is more stable than sigmoid
```{r}
library(torch)

alzheimers_net = nn_module(
  "class_net",
  
  initialize = function(){
    self$layer1 = nn_linear(in_features = ncol(x), out_features = 64)
    self$layer2 = nn_linear(in_features = 64, out_features = 32)
    self$output = nn_linear(in_features = 32, out_features = 1)
  },
  forward = function(x){
    x %>%
      self$layer1() %>%
      nnf_relu() %>%
      self$layer2() %>%
      nnf_relu() %>%
      self$output()
  }
)
```
# Convert columns to numeric
```{r}
alzheimers_data = alzheimers_data[, -which(names(alzheimers_data) == "DoctorInCharge")]
alzheimers_data = alzheimers_data[, -which(names(alzheimers_data) == "PatientID")]

alzheimers_data$Gender <- as.numeric(factor(alzheimers_data$Gender))
alzheimers_data$Ethnicity <- as.numeric(factor(alzheimers_data$Ethnicity))
alzheimers_data$EducationLevel <- as.numeric(factor(alzheimers_data$EducationLevel))
alzheimers_data$Smoking <- as.numeric(factor(alzheimers_data$Smoking))
alzheimers_data$AlcoholConsumption <- as.numeric(factor(alzheimers_data$AlcoholConsumption))
alzheimers_data$PhysicalActivity <- as.numeric(factor(alzheimers_data$PhysicalActivity))
alzheimers_data$DietQuality <- as.numeric(factor(alzheimers_data$DietQuality))
alzheimers_data$SleepQuality <- as.numeric(factor(alzheimers_data$SleepQuality))
alzheimers_data$FamilyHistoryAlzheimers <- as.numeric(factor(alzheimers_data$FamilyHistoryAlzheimers))
alzheimers_data$CardiovascularDisease <- as.numeric(factor(alzheimers_data$CardiovascularDisease))
alzheimers_data$Diabetes <- as.numeric(factor(alzheimers_data$Diabetes))
alzheimers_data$Depression <- as.numeric(factor(alzheimers_data$Depression))
alzheimers_data$HeadInjury <- as.numeric(factor(alzheimers_data$HeadInjury))
alzheimers_data$Hypertension <- as.numeric(factor(alzheimers_data$Hypertension))

# Normalize the numeric columns, but the -ncol removes the last column which is diagnosis because we dont want to scale binary response

alzheimers_data[, -ncol(alzheimers_data)] <- scale(alzheimers_data[, -ncol(alzheimers_data)])

#Applies as.numeric to all data because it wasnt working with above earlier
alzheimers_data = data.frame(lapply(alzheimers_data, as.numeric))

#See classifications in table
table(alzheimers_data$Diagnosis)

```
# Split Data and Convert Into Tensors
```{r}
x = as.matrix(alzheimers_data[, -32]) #All but diagnose column
y = alzheimers_data$Diagnosis

x_tensor = torch_tensor(as.matrix(x), dtype = torch_float())
y_tensor = torch_tensor(as.numeric(y), dtype = torch_float())
y_tensor
```
# Neural Net Steps with K-Folds cross validation
```{r}
library(caret)

# Define K-fold cross-validation parameters
k <- 10
folds <- createFolds(y, k = k, list = TRUE, returnTrain = TRUE)

result <- numeric(k)

for (i in 1:k) {
  cat("Fold:", i, "\n")
  
  # Split the data
  train_indices <- folds[[i]]
  test_indices <- setdiff(seq_len(nrow(alzheimers_data)), train_indices)
  
  x_train <- x_tensor[train_indices, ]
  y_train <- y_tensor[train_indices]$unsqueeze(2) 
  x_test <- x_tensor[test_indices, ]
  y_test <- y_tensor[test_indices]$unsqueeze(2)    
  # Initialize the model
  neural_model <- alzheimers_net()
  optimizer <- optim_adam(neural_model$parameters, lr = 0.001)
  criterion <- nn_bce_with_logits_loss()

  # Training loop
  num_epochs <- 100
  for (epoch in 1:num_epochs) {
    optimizer$zero_grad()
    outputs <- neural_model(x_train)
    loss <- criterion(outputs, y_train)
    loss$backward()
    optimizer$step()
    
    
    if (epoch %% 10 == 0) {
    cat("Epoch:", epoch, "Loss:", loss$item(), "\n")
    }
  }
  
  # Evaluate the model
  neural_model$eval()
  with_no_grad({
    outputs <- neural_model(x_test)
    predictions <- torch_sigmoid(outputs) > 0.5
    accuracy <- mean(as_array(predictions) == as_array(y_test))
    result[i] <- accuracy
  })
}

# Print cross-validation results
cat("Cross-Validation Accuracy:", mean(result), "\n")

```